{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 개요\n",
    "\n",
    "본 노트북의 목적은 학습이 끝난 실험의 성능이 실제로 어떠한가를 다각적으로 검증하고, clustering을 classification으로 변환하였을 때 어떠한 결과가 나오는가를 확인하기 위함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigma 실험\n",
    "\n",
    "loss sigma를 1.0으로 두었을 때 FM 점수가 0.4대로 매우 높게 나오는 모델이 발견됨. 이를 살펴보고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.cluster import (\n",
    "    DBSCAN, \n",
    "    AffinityPropagation, \n",
    "    HDBSCAN\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/workspace/\")\n",
    "\n",
    "from dataset import *\n",
    "from model import speaker_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_path': 'data/pdnc/novels',\n",
       " 'save_dir': 'models_storage/cluster/l2_epsilon',\n",
       " 'model_state_file': 'models_storage/cluster/l2_epsilon/model_2024-07-04_23_35.pth',\n",
       " 'feature_dimension': 2048,\n",
       " 'decoder_hidden': 1024,\n",
       " 'feature_freedom': 1,\n",
       " 'seed': 201456,\n",
       " 'learning_rate': 2e-06,\n",
       " 'adam_epsilon': 1e-08,\n",
       " 'warmup_steps': 0,\n",
       " 'weight_decay': 0.0,\n",
       " 'saved_anchor_num': 2,\n",
       " 'detach_mems_step': 5,\n",
       " 'loss_sig': 1.0,\n",
       " 'loss_epsilon': 10,\n",
       " 'early_stopping_criteria': 5,\n",
       " 'max_epochs': 15,\n",
       " 'book_train_iter': 2,\n",
       " 'reload_from_files': False,\n",
       " 'expand_filepaths_to_save_dir': True,\n",
       " 'log_json_file': 'models_storage/cluster/l2_epsilon/log/train_at_2024-07-04_23_35.json',\n",
       " 'catch_keyboard_interrupt': True,\n",
       " 'test': False,\n",
       " 'log_dir': 'models_storage/cluster/l2_epsilon/log/',\n",
       " 'cuda': True,\n",
       " 'stop_early': False,\n",
       " 'early_stopping_step': 0,\n",
       " 'early_stopping_best_val': 0.4043824772004873,\n",
       " 'epoch_index': 15,\n",
       " 'train_loss': [0.14698808098290767,\n",
       "  0.505345346411964,\n",
       "  0.27858838364638144,\n",
       "  0.09625305916237648,\n",
       "  0.25176437720063033,\n",
       "  0.47783417577844084,\n",
       "  0.17145052574101532,\n",
       "  0.2381024606477314,\n",
       "  0.15653424639311414,\n",
       "  0.19196423174756713,\n",
       "  0.23505183776873423,\n",
       "  0.14345191694424836,\n",
       "  0.2191595353585255,\n",
       "  0.20512842449707605,\n",
       "  0.4983570039452566,\n",
       "  0.1661275657194637,\n",
       "  0.24020477560652803,\n",
       "  0.1027733662207749,\n",
       "  0.17116451798354054,\n",
       "  0.20024113969495935,\n",
       "  0.4161004251744374,\n",
       "  0.19815260009921118,\n",
       "  0.26560629134635233,\n",
       "  0.1473214089551388,\n",
       "  0.28774490245566603,\n",
       "  0.17387662385741043,\n",
       "  0.2931777645206572,\n",
       "  0.14947244619666522,\n",
       "  0.23778587070910018,\n",
       "  0.23401123444376165,\n",
       "  0.2055947874498439,\n",
       "  0.5135698626935483,\n",
       "  0.16921058962156843,\n",
       "  0.1887471707885274,\n",
       "  0.16605853028257234,\n",
       "  0.20877766244472368,\n",
       "  0.13779743150528953,\n",
       "  0.15882428917240457,\n",
       "  0.2204161662001488,\n",
       "  0.10596872483132896,\n",
       "  0.3714229769880082,\n",
       "  0.46905885188019336,\n",
       "  0.2511703434274406,\n",
       "  0.2247649049202882,\n",
       "  0.2065237539155143,\n",
       "  0.17867341308456444,\n",
       "  0.5280622192552353,\n",
       "  0.09884079018872696,\n",
       "  0.28612003492913207,\n",
       "  0.4493699940974112,\n",
       "  0.15333465013973552,\n",
       "  0.15876427254389802,\n",
       "  0.24867600493336706,\n",
       "  0.2792676032425625,\n",
       "  0.17148110107139525,\n",
       "  0.16329770198991872,\n",
       "  0.15871335221521987,\n",
       "  0.2703429909165927,\n",
       "  0.10033912933876615,\n",
       "  0.26859725839063875,\n",
       "  0.16823623390914738,\n",
       "  0.14715320319865052,\n",
       "  0.4721276334321939,\n",
       "  0.3008037739059341,\n",
       "  0.14834569363458502,\n",
       "  0.13745131786842169,\n",
       "  0.22620575177298188,\n",
       "  0.4237541364707861,\n",
       "  0.22262919415517296,\n",
       "  0.1945239724857467,\n",
       "  0.2273091454590635,\n",
       "  0.2319735007492234,\n",
       "  0.19514274422468894,\n",
       "  0.16092345630765026,\n",
       "  0.23659470675137698,\n",
       "  0.1521282103141958,\n",
       "  0.08405579795220411,\n",
       "  0.23916513619266147,\n",
       "  0.12838655231217078,\n",
       "  0.24228370237243427,\n",
       "  0.1355775067911699,\n",
       "  0.4831858237631075,\n",
       "  0.13017000313600643,\n",
       "  0.49168363645510793,\n",
       "  0.19663173661074246,\n",
       "  0.15612008978707204,\n",
       "  0.23415766964395215,\n",
       "  0.17144295978264296,\n",
       "  0.1811475504232063,\n",
       "  0.4218325033517821,\n",
       "  0.1576204147394114,\n",
       "  0.12403483122388985,\n",
       "  0.09490234418391591,\n",
       "  0.11656310752620741,\n",
       "  0.06704217647232764,\n",
       "  0.0840590476676987,\n",
       "  0.3419811536213947,\n",
       "  0.203461187794095,\n",
       "  0.325547184849997,\n",
       "  0.12834019912696903,\n",
       "  0.129357397890339,\n",
       "  0.05984701878076291,\n",
       "  0.4727070901887005,\n",
       "  0.22802916995380657,\n",
       "  0.10053124988381096,\n",
       "  0.012953569648112347,\n",
       "  0.08657425164419302,\n",
       "  0.08744575690512768,\n",
       "  0.19780093507733257,\n",
       "  0.1797752705297329,\n",
       "  -0.0399372356662251,\n",
       "  -0.0030096458373734328,\n",
       "  0.10967703436076634,\n",
       "  0.1319729541365927,\n",
       "  -0.005236874639580065,\n",
       "  0.16001073381499137,\n",
       "  0.07402460741617961,\n",
       "  0.1272729514601148,\n",
       "  0.1885260257951742,\n",
       "  0.09519970054202777,\n",
       "  -0.03976812909586909,\n",
       "  -0.1170527511789086,\n",
       "  0.06189329979741966,\n",
       "  0.01523662350309635,\n",
       "  0.06774410549484347,\n",
       "  0.4406945181629026,\n",
       "  -0.05322241361765193,\n",
       "  0.0008003106815781431,\n",
       "  0.10621208667709195,\n",
       "  -0.11889084504538588,\n",
       "  0.11188313638565611,\n",
       "  0.10306200781121683,\n",
       "  -0.26140195917699244,\n",
       "  0.014040260521436743,\n",
       "  -0.04036756484394888,\n",
       "  0.41877462789870623,\n",
       "  0.061530697906873155,\n",
       "  -0.14206898638716106,\n",
       "  0.22270778104968703,\n",
       "  0.04519792467951725,\n",
       "  -0.24485641655444773,\n",
       "  -0.20355072104594346,\n",
       "  -0.14447928523968323,\n",
       "  0.09494269039312198,\n",
       "  0.09400039427162382,\n",
       "  -0.11076471224547839,\n",
       "  0.38277202447405057,\n",
       "  -0.03139735208066413,\n",
       "  -0.5284891407555805,\n",
       "  -0.2046559284680668,\n",
       "  -0.0008437627872999141,\n",
       "  0.004871633610236237,\n",
       "  0.16812205009891873,\n",
       "  0.14338882611162967,\n",
       "  0.09819304870466425,\n",
       "  0.045146310947934185,\n",
       "  -0.06740842810806316,\n",
       "  0.10740748965457932,\n",
       "  0.05599920874606043,\n",
       "  -0.035083919004200825,\n",
       "  -0.32923107149466024,\n",
       "  -0.368732551910564,\n",
       "  0.0195369172504839,\n",
       "  0.06110737634478085,\n",
       "  -0.3628825238307767,\n",
       "  -0.017327472564711902,\n",
       "  0.4814240617618427,\n",
       "  -0.20968727946197957,\n",
       "  0.13355019847263716,\n",
       "  0.14209778723006428,\n",
       "  -0.4388840450599574,\n",
       "  -0.1508481839432866,\n",
       "  0.13656763226683652,\n",
       "  -0.8513824778247658,\n",
       "  -0.2261037581888961,\n",
       "  0.4145413988819935,\n",
       "  -0.037773885033313415,\n",
       "  -0.06935629734605832,\n",
       "  -0.03487485783279994,\n",
       "  0.08276545858711169,\n",
       "  0.18053389304536133,\n",
       "  -0.42494425435864636,\n",
       "  -0.6826595275385173,\n",
       "  -0.45619316661335396,\n",
       "  0.11164248890628252,\n",
       "  -0.011504833583798404,\n",
       "  0.012378861819658749,\n",
       "  0.016319514749949034,\n",
       "  0.020068690619737442,\n",
       "  -0.6087715398474246,\n",
       "  0.3363667997900164,\n",
       "  -0.1483466005706957,\n",
       "  -0.3048751949130297,\n",
       "  0.03725608345243849,\n",
       "  -1.261185753294326,\n",
       "  0.98686872498295,\n",
       "  -1.2080743983073419,\n",
       "  0.10241197658794436,\n",
       "  -0.19843956777649668,\n",
       "  -0.12192407560195243,\n",
       "  -0.0678988537835854,\n",
       "  -0.2809509187818796,\n",
       "  -1.2918205106559655,\n",
       "  -0.558869211657421,\n",
       "  -0.2948645183023081,\n",
       "  -0.2394557788511015,\n",
       "  0.17997901643454514,\n",
       "  -0.06588661049718755,\n",
       "  0.593529285501241,\n",
       "  -0.5098882527036631],\n",
       " 'train_acc': [],\n",
       " 'val_loss': [0.200142003595829,\n",
       "  0.30529169272631407,\n",
       "  0.14872954972088337,\n",
       "  0.18973937444388866,\n",
       "  0.07234279159456491,\n",
       "  0.17713244818150997,\n",
       "  0.25491427164524794,\n",
       "  0.0821414333768189,\n",
       "  0.0321137011051178,\n",
       "  -0.023355331271886826,\n",
       "  0.006179228425025942,\n",
       "  -0.14418650977313519,\n",
       "  -0.12335785664618015,\n",
       "  -0.13400356378406286,\n",
       "  -0.11414450779557228],\n",
       " 'val_acc': [0.1076099455055464,\n",
       "  0.14593744973444436,\n",
       "  0.16335611745836637,\n",
       "  0.4043824772004873,\n",
       "  0.3866223315996423,\n",
       "  0.38922993895578667,\n",
       "  0.34129880865706086,\n",
       "  0.3452079226889117,\n",
       "  0.35511208158307056,\n",
       "  0.3319501976934752,\n",
       "  0.3336974690393339,\n",
       "  0.334117263214489,\n",
       "  0.32369821147104305,\n",
       "  0.33009818734219015,\n",
       "  0.33762895974821516],\n",
       " 'test_loss': -1,\n",
       " 'test_acc': -1,\n",
       " 'model_filename': 'models_storage/cluster/l2_epsilon/model.pth'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_log_path = \"/workspace/models_storage/cluster/l2_epsilon/log/train_at_2024-07-04_23_35.json\"\n",
    "train_log = []\n",
    "\n",
    "with open(train_log_path, mode=\"r\") as fp:\n",
    "    train_log = json.loads(fp.read())\n",
    "\n",
    "train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of InfiniBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.8.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.5.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.11.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.0.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.3.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.1.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.7.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.9.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.4.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.6.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.10.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.2.attention.self.fastweight_mem.head_gates']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import (\n",
    "    BertConfig, \n",
    "    BertTokenizer\n",
    ")\n",
    "\n",
    "# 모델 로드\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "data_set = PDNCDataset(train_log[\"dataset_path\"], tokenizer)\n",
    "\n",
    "\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_config.decoder_intermediate_size = train_log[\"decoder_hidden\"]\n",
    "bert_config.feature_dimension = train_log[\"feature_dimension\"]\n",
    "bert_config.feature_freedom = train_log[\"feature_freedom\"]\n",
    "    \n",
    "model = speaker_clustering.SpeakerClusterModel(bert_config)\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(\"/workspace/\", train_log[\"model_state_file\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_model_prediction(batch_dict, tokenizer, model, device):\n",
    "    seq_length = np.sum(batch_dict[\"x_length\"])\n",
    "    if seq_length > tokenizer.model_max_length:\n",
    "        # 문단 길이가 context window를 초과할 때\n",
    "        # 문단에서 발화자가 달라지지 않고 전체가 다 한 사람이 말한 것이거나 설명문이거나\n",
    "        # 여러 번 출력을 받아 pooling하는 방식으로 해결\n",
    "        process_num = (\n",
    "            seq_length // tokenizer.model_max_length) + 1\n",
    "        avg_pool = nn.AvgPool2d(\n",
    "            kernel_size=(process_num, 1), stride=1)\n",
    "        pred_features = []\n",
    "        error_accum = 0\n",
    "                        \n",
    "        for i in range(process_num):\n",
    "            x_i = batch_dict['x'][0][i * tokenizer.model_max_length - error_accum: min(\n",
    "                seq_length, (i + 1) * tokenizer.model_max_length) - error_accum].reshape((1, -1))\n",
    "            if x_i[0][0] != tokenizer.cls_token_id:\n",
    "                x_i = batch_dict['x'][0][i * tokenizer.model_max_length - error_accum: min(\n",
    "                    seq_length, (i + 1) * tokenizer.model_max_length - 1) - error_accum].reshape((1, -1))\n",
    "                x_i = torch.cat(\n",
    "                    (torch.tensor([[tokenizer.cls_token_id]]).to(device), x_i), dim=1)\n",
    "                error_accum += 1\n",
    "\n",
    "            pred = model(input_ids=x_i, cls_idx=[0])\n",
    "            pred_features.append(pred[0][0])\n",
    "\n",
    "        pred_features = torch.cat(pred_features, dim=0).reshape(\n",
    "            (1, process_num, pred_features[0].shape[0]))\n",
    "        y_pred = avg_pool(pred_features)\n",
    "\n",
    "        y_pred = (y_pred.squeeze(0), None)\n",
    "    else:\n",
    "        y_pred = model(input_ids=batch_dict['x'], cls_idx=batch_dict[\"cls_index\"])\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee5fe34c2344f029f4b65b7791a1f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "\n",
    "val_bar = tqdm.tqdm(desc=\"\",\n",
    "                    total=10,\n",
    "                    position=2, \n",
    "                    leave=True)\n",
    "\n",
    "book_idx = 3\n",
    "\n",
    "data_set.set_book(book_idx)\n",
    "\n",
    "batch_generator = generate_pdnc_batches(data_set,\n",
    "                                        max_seq_length=tokenizer.model_max_length,\n",
    "                                        device=\"cpu\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "val_bar.n = 0\n",
    "val_bar.total = data_set.get_num_batches(1)\n",
    "val_bar.desc = 'book{0} inference'.format(book_idx)\n",
    "\n",
    "cls_features = []\n",
    "speakers = []\n",
    "\n",
    "for batch_index, batch_dict in enumerate(batch_generator):\n",
    "    y_pred = get_model_prediction(batch_dict, tokenizer, model, \"cpu\")\n",
    "    \n",
    "    cls_features.extend([feature.detach().cpu().numpy() for feature in y_pred[0]])\n",
    "    speakers.extend(batch_dict[\"speaker\"])\n",
    "    \n",
    "    val_bar.update(len(batch_dict[\"speaker\"]))\n",
    "    model.detach_memories_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.028851913534258204, 0.13231858914640712, 0.047373985059676244, None)\n"
     ]
    }
   ],
   "source": [
    "from metric import *\n",
    "\n",
    "res = calc_v_measure_with_hdb(np.array(cls_features), speakers)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.36698396254923576, None)\n"
     ]
    }
   ],
   "source": [
    "res = calc_adjusted_rand_with_hdb(np.array(cls_features), speakers)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb = HDBSCAN(store_centers=\"centroid\").fit(np.array(cls_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdb_leaf = HDBSCAN(store_centers=\"centroid\", cluster_selection_method=\"leaf\").fit(np.array(cls_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hdb_leaf.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = hdb.dbscan_clustering(cut_distance=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n",
      "3191\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "print(len(labels[labels != -1]))\n",
    "print(len(labels))\n",
    "print(len(set(labels[labels != -1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 15, 20, 20, 20, 20, 16, 16, 16, 16, 16,  3, 14, 14, 14, 12, 12,\n",
       "       12, 12, 12, 12, 17, 17, 17, 17, 17, 17, 17, 17, 17,  3,  2, 19, 19,\n",
       "       19, 19, 19, 19, 19, 19, 19,  3,  2, 14,  2, 14, 14, 21, 21, 21, 21,\n",
       "        4,  4,  4,  3,  6,  6,  0,  3, 24, 24, 24, 24, 24, 24, 24, 24, 24,\n",
       "       24,  3,  2, 19, 19, 19, 19, 19, 19, 19,  4, 20, 25, 25, 25, 25, 25,\n",
       "       25, 25, 25,  0,  8,  8,  8,  8,  8,  8,  8,  3,  5,  5,  5,  5,  5,\n",
       "        5,  2, 22, 22, 22, 22,  4,  4, 23, 23, 23,  3, 23, 23,  1,  1,  3,\n",
       "        5,  5,  3, 10, 10, 10, 10, 10,  4,  3,  2,  3, 11, 11, 11, 11, 11,\n",
       "       11, 11,  0,  0,  4,  4,  4,  4,  3, 18,  3, 15, 15, 15, 15, 15, 15,\n",
       "       15, 15, 15, 15,  1,  1,  1,  4,  1,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  3, 21,  3,  1,  4,  4, 22, 22, 22,  4,  7,  7,  7,  7,  7,  7,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13,  3, 18, 18, 18, 18, 18, 18,  0,\n",
       "        3, 15, 15, 20, 20, 20, 20, 20, 20, 15, 15, 15, 15,  4,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  0,  0,  3, 14,  1,  4, 14])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[labels != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_idx = dict()\n",
    "\n",
    "speaker_list = list(set(speakers))\n",
    "random.shuffle(speaker_list)\n",
    "\n",
    "for i, l in enumerate(speaker_list):\n",
    "    labels_to_idx[l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mansbridge': 0,\n",
       " 'The Driver': 1,\n",
       " 'The Child': 2,\n",
       " 'Fraulein Mosebach': 3,\n",
       " 'Charles Wilcox': 4,\n",
       " 'Frieda': 5,\n",
       " 'Tibby': 6,\n",
       " 'Helen': 7,\n",
       " 'Leonard': 8,\n",
       " 'Dolly': 9,\n",
       " 'Myra': 10,\n",
       " 'Mr. Wilcox': 11,\n",
       " 'A Girl Opposite': 12,\n",
       " 'Paul': 13,\n",
       " 'Uncle Ernst': 14,\n",
       " 'Margaret': 15,\n",
       " 'Henry': 16,\n",
       " '': 17,\n",
       " 'Albert Fussell': 18,\n",
       " 'Mr. Cunningham': 19,\n",
       " 'Mrs. Plynlimmon': 20,\n",
       " 'The Parlourmaid': 21,\n",
       " 'The Reader Of The Paper': 22,\n",
       " \"His Father'S Chauffeur\": 23,\n",
       " 'Madge': 24,\n",
       " 'Evie': 25,\n",
       " 'Mr. Dealtry': 26,\n",
       " 'Blanche': 27,\n",
       " 'A Friend Of Mrs. Wilcox': 28,\n",
       " 'Angelo': 29,\n",
       " 'Mrs. Warrington': 30,\n",
       " 'Jacky': 31,\n",
       " 'Herr Liesecke': 32,\n",
       " 'The Ticket Boy': 33,\n",
       " 'Mr. Cahill': 34,\n",
       " 'Mrs. Wilcox': 35,\n",
       " 'An Earnest Girl': 36,\n",
       " 'Tom': 37,\n",
       " 'Miss Avery': 38,\n",
       " 'Aunt Juley': 39,\n",
       " 'A Young Man Low Down In The Education Office': 40,\n",
       " 'Colonel Fussell': 41,\n",
       " 'A Haughty And Magnificent Nephew': 42,\n",
       " 'Laura': 43,\n",
       " 'A Little Boy': 44,\n",
       " 'Mrs. Bast': 45,\n",
       " 'Crane': 46}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_indices = [labels_to_idx[l] for l in speakers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003934294927734551\n"
     ]
    }
   ],
   "source": [
    "fm = metrics.adjusted_rand_score(labels_true=label_indices, labels_pred=labels)\n",
    "\n",
    "print(fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[labels == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Margaret',\n",
       " 'Margaret',\n",
       " 'Margaret',\n",
       " 'Margaret',\n",
       " 'Margaret',\n",
       " 'Margaret',\n",
       " 'Aunt Juley',\n",
       " 'Helen']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_mask = (labels == 25)\n",
    "clsutered_speaker = [speaker for idx, speaker in enumerate(speakers) if cluster_mask[idx]]\n",
    "\n",
    "clsutered_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Margaret': 6, 'Aunt Juley': 1, 'Helen': 1})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "speaker_count = Counter(clsutered_speaker)\n",
    "\n",
    "speaker_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(np.array(cls_features))\n",
    "\n",
    "ap = AffinityPropagation().fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ap.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n",
      "3191\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(labels[labels != -1]))\n",
    "print(len(labels))\n",
    "print(len(set(labels[labels != -1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
