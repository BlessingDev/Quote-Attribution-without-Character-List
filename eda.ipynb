{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 bert 모델을 편집할 수 있는지 확인해보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/workspace/\")\n",
    "\n",
    "from model.custom_bert_model import InfiniBertModel\n",
    "from model.speaker_clustering import SpeakerClusterModel\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertConfig\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT 사전학습 모델\n",
    "\n",
    "BERT 사전학습 모델을 불러오는 코드\n",
    "\n",
    "HuggingFace BERT를 수정하여 infini-attention 추가\n",
    "\n",
    "infini BERT에 사전학습 가중치가 로드되는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of InfiniBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.9.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.7.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.11.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.10.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.1.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.5.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.3.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.8.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.6.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.0.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.2.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.4.attention.self.fastweight_mem.head_gates']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"test\": \"test\",\n",
      "  \"transformers_version\": \"4.32.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_config.test = \"test\"\n",
    "model = InfiniBertModel.from_pretrained(\"bert-base-uncased\", config = bert_config)\n",
    "config = model.config\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What Does the Sea Say to Shore\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2515, 1996, 2712, 2360, 2000, 5370,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.encoder.init_memories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.forward(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0676,  0.1169, -0.0588,  ..., -0.2462,  0.0030,  0.2178],\n",
       "         [ 0.3927,  0.0140, -0.3862,  ...,  0.7322, -0.1591, -0.4914],\n",
       "         [ 0.5550,  0.2541,  0.3846,  ..., -0.0214, -0.2755,  0.4120],\n",
       "         ...,\n",
       "         [ 0.2774, -0.0327,  0.2194,  ..., -0.0293,  0.0623,  0.7460],\n",
       "         [-0.3367, -0.3397, -0.3121,  ..., -0.1021,  0.2643, -0.0252],\n",
       "         [ 0.8737,  0.2135, -0.4063,  ...,  0.0282, -0.5712, -0.4220]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.cls_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"What Does the Sea Say to Shore\"\n",
    "text2 = \"What should we do?\"\n",
    "result = tokenizer.batch_encode_plus([text1, text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2054, 2515, 1996, 2712, 2360, 2000, 5370, 102], [101, 2054, 2323, 2057, 2079, 1029, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# speaker cluster 모델 실험\n",
    "\n",
    "speaker cluster 모델 구현\n",
    "\n",
    "speaker cluster 모델 잘 작동하는지 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of InfiniBertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.11.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.5.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.10.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.2.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.8.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.1.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.7.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.4.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.3.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.6.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.0.attention.self.fastweight_mem.head_gates', 'bert.encoder.layer.9.attention.self.fastweight_mem.head_gates']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_config = BertConfig.from_pretrained(\"bert-base-uncased\")\n",
    "bert_config.decoder_intermediate_size = 1524\n",
    "bert_config.feature_dimension = 500\n",
    "\n",
    "model = SpeakerClusterModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_batch_encode_result(encoded_result: dict):\n",
    "    input_ids = []\n",
    "    token_type_ids = []\n",
    "    attention_mask = []\n",
    "    for ids in encoded_result[\"input_ids\"]:\n",
    "        input_ids.extend(ids)\n",
    "    \n",
    "    for type_ids in encoded_result[\"token_type_ids\"]:\n",
    "        token_type_ids.extend(type_ids)\n",
    "    \n",
    "    for masks in encoded_result[\"attention_mask\"]:\n",
    "        attention_mask.extend(masks)\n",
    "        \n",
    "    return {\n",
    "        \"input_ids\": torch.Tensor([input_ids]).int(), \n",
    "        \"token_type_ids\": torch.Tensor([token_type_ids]).int(),\n",
    "        \"attention_mask\": torch.Tensor([attention_mask]).int()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"What Does the Sea Say to Shore\"\n",
    "text2 = \"What should we do?\"\n",
    "result = tokenizer.batch_encode_plus([text1, text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_result = concat_batch_encode_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2054, 2515, 1996, 2712, 2360, 2000, 5370,  102,  101, 2054, 2323,\n",
       "          2057, 2079, 1029,  102]], dtype=torch.int32),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.int32),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(**concat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 구성\n",
    "\n",
    "데이터가 생긴 꼴을 살피고, 데이터셋 파일을 구성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/workspace/\")\n",
    "\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>novel</th>\n",
       "      <th>author</th>\n",
       "      <th>folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Room With A View</td>\n",
       "      <td>E. M. Forster</td>\n",
       "      <td>ARoomWithAView</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Age of Innocence</td>\n",
       "      <td>Edith Wharton</td>\n",
       "      <td>AgeOfInnocence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>AliceInWonderland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anne Of Green Gables</td>\n",
       "      <td>Lucy Maud Montgomery</td>\n",
       "      <td>AnneOfGreenGables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Daisy Miller</td>\n",
       "      <td>Henry James</td>\n",
       "      <td>DaisyMiller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emma</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Emma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A Handful Of Dust</td>\n",
       "      <td>Evelyn Waugh</td>\n",
       "      <td>HandfulOfDust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Howards End</td>\n",
       "      <td>E. M. Forster</td>\n",
       "      <td>HowardsEnd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Night And Day</td>\n",
       "      <td>Virginia Woolf</td>\n",
       "      <td>NightAndDay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Northanger Abbey</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>NorthangerAbbey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Persuasion</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>Persuasion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pride And Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>PrideAndPrejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sense And Sensibility</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>SenseAndSensibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Sign of the Four</td>\n",
       "      <td>Sir Arthur Conan Doyle</td>\n",
       "      <td>SignOfFour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Awakening</td>\n",
       "      <td>Kate Chopin</td>\n",
       "      <td>TheAwakening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Gambler</td>\n",
       "      <td>Fyodor Dostoevsky (Trans. C.J. Hogarth)</td>\n",
       "      <td>TheGambler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Invisible Man</td>\n",
       "      <td>H. G. Wells</td>\n",
       "      <td>TheInvisibleMan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The Man Who Was Thursday</td>\n",
       "      <td>G. K. Chesterton</td>\n",
       "      <td>TheManWhoWasThursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Mysterious Affair At Styles</td>\n",
       "      <td>Agatha Christie</td>\n",
       "      <td>TheMysteriousAffairAtStyles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The Picture Of Dorian Gray</td>\n",
       "      <td>Oscar Wilde</td>\n",
       "      <td>ThePictureOfDorianGray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The Sport Of The Gods</td>\n",
       "      <td>Paul Laurence Dunbar</td>\n",
       "      <td>TheSportOfTheGods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The Sun Also Rises</td>\n",
       "      <td>Ernest Hemingway</td>\n",
       "      <td>TheSunAlsoRises</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               novel                                   author  \\\n",
       "0                 A Room With A View                            E. M. Forster   \n",
       "1               The Age of Innocence                            Edith Wharton   \n",
       "2   Alice's Adventures in Wonderland                            Lewis Carroll   \n",
       "3               Anne Of Green Gables                     Lucy Maud Montgomery   \n",
       "4                       Daisy Miller                              Henry James   \n",
       "5                               Emma                              Jane Austen   \n",
       "6                  A Handful Of Dust                             Evelyn Waugh   \n",
       "7                        Howards End                            E. M. Forster   \n",
       "8                      Night And Day                           Virginia Woolf   \n",
       "9                   Northanger Abbey                              Jane Austen   \n",
       "10                        Persuasion                              Jane Austen   \n",
       "11               Pride And Prejudice                              Jane Austen   \n",
       "12             Sense And Sensibility                              Jane Austen   \n",
       "13              The Sign of the Four                   Sir Arthur Conan Doyle   \n",
       "14                     The Awakening                              Kate Chopin   \n",
       "15                       The Gambler  Fyodor Dostoevsky (Trans. C.J. Hogarth)   \n",
       "16                 The Invisible Man                              H. G. Wells   \n",
       "17          The Man Who Was Thursday                         G. K. Chesterton   \n",
       "18   The Mysterious Affair At Styles                          Agatha Christie   \n",
       "19        The Picture Of Dorian Gray                              Oscar Wilde   \n",
       "20             The Sport Of The Gods                     Paul Laurence Dunbar   \n",
       "21                The Sun Also Rises                         Ernest Hemingway   \n",
       "\n",
       "                         folder  \n",
       "0                ARoomWithAView  \n",
       "1                AgeOfInnocence  \n",
       "2             AliceInWonderland  \n",
       "3             AnneOfGreenGables  \n",
       "4                   DaisyMiller  \n",
       "5                          Emma  \n",
       "6                 HandfulOfDust  \n",
       "7                    HowardsEnd  \n",
       "8                   NightAndDay  \n",
       "9               NorthangerAbbey  \n",
       "10                   Persuasion  \n",
       "11            PrideAndPrejudice  \n",
       "12          SenseAndSensibility  \n",
       "13                   SignOfFour  \n",
       "14                 TheAwakening  \n",
       "15                   TheGambler  \n",
       "16              TheInvisibleMan  \n",
       "17         TheManWhoWasThursday  \n",
       "18  TheMysteriousAffairAtStyles  \n",
       "19       ThePictureOfDorianGray  \n",
       "20            TheSportOfTheGods  \n",
       "21              TheSunAlsoRises  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listofnovels = pd.read_csv('data/pdnc/ListOfNovels.txt')\n",
    "listofnovels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels = []\n",
    "with open('data/pdnc/ListOfNovels.txt', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        novels.append(row[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARoomWithAView\n",
      "Number of characters: 67\n",
      "AgeOfInnocence\n",
      "Number of characters: 55\n",
      "AliceInWonderland\n",
      "Number of characters: 51\n",
      "AnneOfGreenGables\n",
      "Number of characters: 115\n",
      "DaisyMiller\n",
      "Number of characters: 10\n",
      "Emma\n",
      "Number of characters: 18\n",
      "HandfulOfDust\n",
      "Number of characters: 106\n",
      "HowardsEnd\n",
      "Number of characters: 57\n",
      "NightAndDay\n",
      "Number of characters: 54\n",
      "NorthangerAbbey\n",
      "Number of characters: 20\n",
      "Persuasion\n",
      "Number of characters: 35\n",
      "PrideAndPrejudice\n",
      "Number of characters: 82\n",
      "SenseAndSensibility\n",
      "Number of characters: 25\n",
      "SignOfFour\n",
      "Number of characters: 35\n",
      "TheAwakening\n",
      "Number of characters: 22\n",
      "TheGambler\n",
      "Number of characters: 27\n",
      "TheInvisibleMan\n",
      "Number of characters: 31\n",
      "TheManWhoWasThursday\n",
      "Number of characters: 31\n",
      "TheMysteriousAffairAtStyles\n",
      "Number of characters: 30\n",
      "ThePictureOfDorianGray\n",
      "Number of characters: 43\n",
      "TheSportOfTheGods\n",
      "Number of characters: 38\n",
      "TheSunAlsoRises\n",
      "Number of characters: 51\n"
     ]
    }
   ],
   "source": [
    "for novel in novels:\n",
    "    print(novel)\n",
    "\n",
    "    qdf = pd.read_csv('data/pdnc/novels/'+novel+'/quotations.csv', index_col=0)\n",
    "    charDict = pkl.load(open('data/pdnc/novels/'+novel+'/charDict.pkl', 'rb'))\n",
    "    \n",
    "    print(\"Number of characters: {}\".format(len(charDict['id2names'])))\n",
    "                             \n",
    "    with open('data/pdnc/novels/'+novel+'/text.txt', 'r') as f:\n",
    "        ntext = f.read().strip()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qTextArr</th>\n",
       "      <th>qSpan</th>\n",
       "      <th>qText</th>\n",
       "      <th>speaker</th>\n",
       "      <th>addressee</th>\n",
       "      <th>qType</th>\n",
       "      <th>refExp</th>\n",
       "      <th>menTexts</th>\n",
       "      <th>menSpans</th>\n",
       "      <th>menEnts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q0</th>\n",
       "      <td>['I know a girl in Strasbourg who can show us ...</td>\n",
       "      <td>[[6412, 6465]]</td>\n",
       "      <td>I know a girl in Strasbourg who can show us th...</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Frances Clyne', 'Robert Cohn']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I said</td>\n",
       "      <td>[['us']]</td>\n",
       "      <td>[[[6453, 6455]]]</td>\n",
       "      <td>[[['Jake Barnes', 'Robert Cohn']]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>[\"She's been there two years and knows everyth...</td>\n",
       "      <td>[[6554, 6654]]</td>\n",
       "      <td>She's been there two years and knows everythin...</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Frances Clyne', 'Robert Cohn']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I thought it was accidental and went on</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>['Hell,', 'why go to Strasbourg? We could go u...</td>\n",
       "      <td>[[6777, 6782], [6793, 6860]]</td>\n",
       "      <td>Hell, why go to Strasbourg? We could go up to ...</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Frances Clyne', 'Robert Cohn']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I said</td>\n",
       "      <td>[[], ['We']]</td>\n",
       "      <td>[[], [[6815, 6817]]]</td>\n",
       "      <td>[[], [['Jake Barnes', 'Robert Cohn']]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>[\"For God's sake,\", \"why did you say that abou...</td>\n",
       "      <td>[[7015, 7030], [7042, 7121]]</td>\n",
       "      <td>For God's sake, why did you say that about tha...</td>\n",
       "      <td>Robert Cohn</td>\n",
       "      <td>['Jake Barnes']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>he said</td>\n",
       "      <td>[[], ['you', 'you', 'Frances']]</td>\n",
       "      <td>[[], [[7050, 7053], [7105, 7108], [7113, 7120]]]</td>\n",
       "      <td>[[], [['Jake Barnes'], ['Jake Barnes'], ['Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>['No, why should I? If I know an American girl...</td>\n",
       "      <td>[[7125, 7226]]</td>\n",
       "      <td>No, why should I? If I know an American girl t...</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Robert Cohn']</td>\n",
       "      <td>Implicit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[['Frances']]</td>\n",
       "      <td>[[[7218, 7225]]]</td>\n",
       "      <td>[[['Frances Clyne']]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2605</th>\n",
       "      <td>['Want to go for a ride?', 'Want to ride throu...</td>\n",
       "      <td>[[363401, 363423], [363434, 363464]]</td>\n",
       "      <td>Want to go for a ride? Want to ride through th...</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Brett Ashley']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I said</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2606</th>\n",
       "      <td>['Right,', \"I haven't seen Madrid. I should se...</td>\n",
       "      <td>[[363468, 363474], [363489, 363532]]</td>\n",
       "      <td>Right, I haven't seen Madrid. I should see Mad...</td>\n",
       "      <td>Brett Ashley</td>\n",
       "      <td>['Jake Barnes']</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>Brett said</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2607</th>\n",
       "      <td>[\"I'll finish this,\"]</td>\n",
       "      <td>[[363536, 363553]]</td>\n",
       "      <td>I'll finish this,</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Brett Ashley']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I said</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2608</th>\n",
       "      <td>['Oh, Jake,', 'we could have had such a damned...</td>\n",
       "      <td>[[364182, 364191], [364206, 364257]]</td>\n",
       "      <td>Oh, Jake, we could have had such a damned good...</td>\n",
       "      <td>Brett Ashley</td>\n",
       "      <td>['Jake Barnes']</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>Brett said</td>\n",
       "      <td>[['Jake'], ['we']]</td>\n",
       "      <td>[[[364186, 364190]], [[364206, 364208]]]</td>\n",
       "      <td>[[['Jake Barnes']], [['Jake Barnes', 'Brett As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2609</th>\n",
       "      <td>['Yes,', \"Isn't it pretty to think so?\"]</td>\n",
       "      <td>[[364392, 364396], [364407, 364435]]</td>\n",
       "      <td>Yes, Isn't it pretty to think so?</td>\n",
       "      <td>Jake Barnes</td>\n",
       "      <td>['Brett Ashley']</td>\n",
       "      <td>Anaphoric</td>\n",
       "      <td>I said</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "      <td>[[], []]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2610 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                qTextArr  \\\n",
       "qId                                                        \n",
       "Q0     ['I know a girl in Strasbourg who can show us ...   \n",
       "Q1     [\"She's been there two years and knows everyth...   \n",
       "Q2     ['Hell,', 'why go to Strasbourg? We could go u...   \n",
       "Q3     [\"For God's sake,\", \"why did you say that abou...   \n",
       "Q4     ['No, why should I? If I know an American girl...   \n",
       "...                                                  ...   \n",
       "Q2605  ['Want to go for a ride?', 'Want to ride throu...   \n",
       "Q2606  ['Right,', \"I haven't seen Madrid. I should se...   \n",
       "Q2607                              [\"I'll finish this,\"]   \n",
       "Q2608  ['Oh, Jake,', 'we could have had such a damned...   \n",
       "Q2609           ['Yes,', \"Isn't it pretty to think so?\"]   \n",
       "\n",
       "                                      qSpan  \\\n",
       "qId                                           \n",
       "Q0                           [[6412, 6465]]   \n",
       "Q1                           [[6554, 6654]]   \n",
       "Q2             [[6777, 6782], [6793, 6860]]   \n",
       "Q3             [[7015, 7030], [7042, 7121]]   \n",
       "Q4                           [[7125, 7226]]   \n",
       "...                                     ...   \n",
       "Q2605  [[363401, 363423], [363434, 363464]]   \n",
       "Q2606  [[363468, 363474], [363489, 363532]]   \n",
       "Q2607                    [[363536, 363553]]   \n",
       "Q2608  [[364182, 364191], [364206, 364257]]   \n",
       "Q2609  [[364392, 364396], [364407, 364435]]   \n",
       "\n",
       "                                                   qText       speaker  \\\n",
       "qId                                                                      \n",
       "Q0     I know a girl in Strasbourg who can show us th...   Jake Barnes   \n",
       "Q1     She's been there two years and knows everythin...   Jake Barnes   \n",
       "Q2     Hell, why go to Strasbourg? We could go up to ...   Jake Barnes   \n",
       "Q3     For God's sake, why did you say that about tha...   Robert Cohn   \n",
       "Q4     No, why should I? If I know an American girl t...   Jake Barnes   \n",
       "...                                                  ...           ...   \n",
       "Q2605  Want to go for a ride? Want to ride through th...   Jake Barnes   \n",
       "Q2606  Right, I haven't seen Madrid. I should see Mad...  Brett Ashley   \n",
       "Q2607                                  I'll finish this,   Jake Barnes   \n",
       "Q2608  Oh, Jake, we could have had such a damned good...  Brett Ashley   \n",
       "Q2609                  Yes, Isn't it pretty to think so?   Jake Barnes   \n",
       "\n",
       "                              addressee      qType  \\\n",
       "qId                                                  \n",
       "Q0     ['Frances Clyne', 'Robert Cohn']  Anaphoric   \n",
       "Q1     ['Frances Clyne', 'Robert Cohn']  Anaphoric   \n",
       "Q2     ['Frances Clyne', 'Robert Cohn']  Anaphoric   \n",
       "Q3                      ['Jake Barnes']  Anaphoric   \n",
       "Q4                      ['Robert Cohn']   Implicit   \n",
       "...                                 ...        ...   \n",
       "Q2605                  ['Brett Ashley']  Anaphoric   \n",
       "Q2606                   ['Jake Barnes']   Explicit   \n",
       "Q2607                  ['Brett Ashley']  Anaphoric   \n",
       "Q2608                   ['Jake Barnes']   Explicit   \n",
       "Q2609                  ['Brett Ashley']  Anaphoric   \n",
       "\n",
       "                                        refExp  \\\n",
       "qId                                              \n",
       "Q0                                      I said   \n",
       "Q1     I thought it was accidental and went on   \n",
       "Q2                                      I said   \n",
       "Q3                                     he said   \n",
       "Q4                                         NaN   \n",
       "...                                        ...   \n",
       "Q2605                                   I said   \n",
       "Q2606                               Brett said   \n",
       "Q2607                                   I said   \n",
       "Q2608                               Brett said   \n",
       "Q2609                                   I said   \n",
       "\n",
       "                              menTexts  \\\n",
       "qId                                      \n",
       "Q0                            [['us']]   \n",
       "Q1                                [[]]   \n",
       "Q2                        [[], ['We']]   \n",
       "Q3     [[], ['you', 'you', 'Frances']]   \n",
       "Q4                       [['Frances']]   \n",
       "...                                ...   \n",
       "Q2605                         [[], []]   \n",
       "Q2606                         [[], []]   \n",
       "Q2607                             [[]]   \n",
       "Q2608               [['Jake'], ['we']]   \n",
       "Q2609                         [[], []]   \n",
       "\n",
       "                                               menSpans  \\\n",
       "qId                                                       \n",
       "Q0                                     [[[6453, 6455]]]   \n",
       "Q1                                                 [[]]   \n",
       "Q2                                 [[], [[6815, 6817]]]   \n",
       "Q3     [[], [[7050, 7053], [7105, 7108], [7113, 7120]]]   \n",
       "Q4                                     [[[7218, 7225]]]   \n",
       "...                                                 ...   \n",
       "Q2605                                          [[], []]   \n",
       "Q2606                                          [[], []]   \n",
       "Q2607                                              [[]]   \n",
       "Q2608          [[[364186, 364190]], [[364206, 364208]]]   \n",
       "Q2609                                          [[], []]   \n",
       "\n",
       "                                                 menEnts  \n",
       "qId                                                       \n",
       "Q0                    [[['Jake Barnes', 'Robert Cohn']]]  \n",
       "Q1                                                  [[]]  \n",
       "Q2                [[], [['Jake Barnes', 'Robert Cohn']]]  \n",
       "Q3     [[], [['Jake Barnes'], ['Jake Barnes'], ['Fran...  \n",
       "Q4                                 [[['Frances Clyne']]]  \n",
       "...                                                  ...  \n",
       "Q2605                                           [[], []]  \n",
       "Q2606                                           [[], []]  \n",
       "Q2607                                               [[]]  \n",
       "Q2608  [[['Jake Barnes']], [['Jake Barnes', 'Brett As...  \n",
       "Q2609                                           [[], []]  \n",
       "\n",
       "[2610 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qType\n",
       "Implicit     1556\n",
       "Explicit      597\n",
       "Anaphoric     456\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf[\"qType\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Implicit'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdf[\"qType\"].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6412, 6465]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(qdf.iloc[0][\"qSpan\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I know a girl in Strasbourg who can show us the town,'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntext[6412:6465]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6785"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = ntext.split('\\n')\n",
    "paragraphs = [p for p in paragraphs if len(p) > 0]\n",
    "len(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2610"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 구현을 위한 실험 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "novels_dir = pathlib.Path(\"data/pdnc/novels/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirs: \n",
      "data/pdnc/novels/AgeOfInnocence\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/SenseAndSensibility\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/DaisyMiller\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/HowardsEnd\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheAwakening\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/NightAndDay\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheSunAlsoRises\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/SignOfFour\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/NorthangerAbbey\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/AliceInWonderland\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheMysteriousAffairAtStyles\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/Emma\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/PrideAndPrejudice\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/ThePictureOfDorianGray\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/ARoomWithAView\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheGambler\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheSportOfTheGods\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheInvisibleMan\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/TheManWhoWasThursday\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/HandfulOfDust\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/Persuasion\n",
      "\n",
      "Dirs: \n",
      "data/pdnc/novels/AnneOfGreenGables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dirs in novels_dir.iterdir():\n",
    "    print(\"Dirs: \")\n",
    "    print(dirs)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
